
\documentclass{acm_proc_article-sp}

\begin{document}

\title{Conversing verses - haiku generation using a LSTM-based auto-encoder matching model}

\numberofauthors{2} 
\author{
\alignauthor
Luka Ernestini\\
       \affaddr{Univerza v Mariboru}\\
       \affaddr{Fakulteta za elektrotehniko, računalništvo in informatiko}\\
       \affaddr{Maribor, Slovenija}\\
       \email{luka.ernestini@student.um.si}

\alignauthor
Niko Uremović\\
       \affaddr{Univerza v Mariboru}\\
       \affaddr{Fakulteta za elektrotehniko, računalništvo in informatiko}\\
       \affaddr{Maribor, Slovenija}\\
       \email{niko.uremovic@um.si}
}

\maketitle
\begin{abstract}

Lorem ipsum

\end{abstract}

% todo: kaj to pomeni
\category{H.4}{Information Systems Applications}{Miscellaneous}

% todo: kaj to pomeni
\terms{Theory}

\keywords{text generation, neural networks, LSTM}

\section{Introduction}

Deep learning is an emerging machine learning approach that can already be seen applied in many industries, including natural language processing. Example use cases include identifying people and objects in images and videos, understanding voice commands (smartphones, cars, smart houses) and providing better results for internet search queries. This technology brought machines the closest they have ever been to how we humans think and talk. Having learned the rules and grammar of our natural language, machines are now able to generate text for various applications that is in some cases indistinguishable from human written text \cite{pawade2018story}.


In the field of natural language processing, many methods deep learning have been developed for text generation. Song, Huang and Ruan \cite{song2019abstractive} achieved Abstractive Text Summarization (ATS) using and LSTM-CNN based ATS framework (ATSDL). You et al. \cite{You_2016_CVPR} researched ways to generate natural language descriptions of images. They proposed a model of semantic attention which combines the established top-down and buttom-up approaches. CNN is used for image classification, followed by LSTM-based RNN for the caption generation. Bhagavatula et al. \cite{bhagavatula2020abductive} investigated the viability of natural language-based abductive reasoning.

One of the obstacles on the field of text generation has been the objective evaluation of the generated text's semantics. While the spelling and grammar correctness are easy to evaluate, the meaning of the generated text can be challenging to evaluate with an automated metric \cite{celikyilmaz2020evaluation}. Some tasks of text generation, such as image captioning or machine translation, where the (suggested) correct generation is known, can use metrics like BLEU \cite{papineni2002bleu} or METEOR \cite{banerjee2005meteor}, to evaluate the quality of the generated text. On the other hand, tasks where the correct generation is not specified (e.g., story \cite{pawade2018story} or poem \cite{zhang2014chinese} generation), the quality of the produced text is usually evaluated by human readers.

We draw inspiration for our research from the work of Luo et al. \cite{luo2018autoencoder}, who propose a novel Auto-Encoder matching model to learn utterance-level semantic dependency for generating everyday dialogue. Three neural networks are used: LSTM for encoding a reply into it's semantical representation, then a feedforward network for mapping the reply semantic into the answer semantic. Lastly a LSTM decoder is used for the sentence generation. Additionally, we found motivation for our work in the success on the field of poem generation by Potash, Romanov and Rumshisky \cite{potash2015ghostwriter}, who demonstrated the generation of rap songs using LSTM, and Netzer et al. \cite{netzer2009gaiku}, who explored the usage of Word Association Norms (WAN) to generate Haiku poetry.

In the paper, we present a novel method for Haiku poetry generation, combining the approaches of generating the first verse using LSTM network, with the Auto-Encoder matching model \cite{luo2018autoencoder} for generating the second and third verse of the Haiku poem as a form of a conversation between the verses. LSTM has proven to be capable of mimicking rhythm, common phrases and even poet's writing style \cite{potash2015ghostwriter}, which we attempt to use for generating the text in a genuine Haiku style, which we describe in the continuation of the work. By using the Auto-Encoder matching model to generate the second and the third verse as an answer to the previous verse, we experiment by adding a sense of conversational bond between the verses.

%- neural networks so zakon
%       - RNN, LSTM - generiranje zgodbe \cite{pawade2018story}
%       - RNN, LSTM - abstracitve text summarization \cite{song2019abstractive}
%       - CNN za image classification, RNN (LSTM) za caption generation - image captioning \cite{You_2016_CVPR}
%       - sklepanje, generiranje hipotez na podlagi naravnega besedila  \cite{bhagavatula2020abductive}
%tezave s katerimi se metode srecujejo (objektivno, avtomatizirano ovrednotenje - semanticna smiselnost besedila)
%       - ponekod lahko uporabimo metrike (kjer imamo target/label text) - image captioning
%              - BLEU \cite{papineni2002bleu}
%              - METEOR \cite{banerjee2005meteor}
%       - ponekod nimamo "pravega"/target/label teksta, in tako niso mozna avtomatska ovretnotenja (ovrednotijo anketiranci, human evaluation)
%              - generiranje kitajskih pesmi \cite{zhang2014chinese}
%              - Haiku generation using seed word(s), associations, heuristics for selecting optimal one \cite{netzer2009gaiku}.
%
%- clanki s katerimi primerjamo, vzamemo za osnovo
%       - generiranje vsakdanjih pogovorov. Tri nevronske mreze se uporabijo za; LSTM za encodanje ene replike v semanticno predstavitev -> simple feedforward mreza za mapiranje semantike replike v semantiko odgovora -> LSTM decoder za tvorjenje stavka iz dobljene nove semantike. \cite{luo2018autoencoder}
%       - generiranje besedila rapperskih pesmi z LSTM \cite{potash2015ghostwriter}.
%       - primerjamo lahko svojo metodo z \cite{netzer2009gaiku}, ki tudi se ukvarja z generiranjem haikujev
%
%- ideja - generiranje haikov, nova metoda
%motivacija
%       - LSTM ima zmoznost posnemati ritem, znacilnosti poezije, kot so uporaba za zvrst znacilnih fraz, posnemanje sloga pisanja \cite{potash2015ghostwriter}
%       - nov nacin navezave med verzi - pogovor (vrstici haikuja, encoder-decoder se pogovarjata)
%metodologija, postopek
%       - generiranje prve vrstice z lstm
%       - generiranje naslednjih vrstic v obliki pogovora (uporaba encoder/decoder pristopa) % implementacija https://github.com/lancopku/AMM

\section{Drugi naslovi}

Lorem ipsum

\section{Conclusions}

Lorem ipsum

\section{Acknowledgments}

The authors acknowledge lorem ipsum.

\bibliographystyle{abbrv}
\bibliography{sigproc}


\balancecolumns

\end{document}
